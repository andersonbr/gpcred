
\section{Programação Genética}

\subsection{Operadores}

\subsection{Fitness}


\section{Credibilidade baseada no Conteúdo}
\label{sec::pg_cred_baseada_conteudo}

Nessa seção apresentamos várias métricas utilizadas na construção dos indivíduos usados pelo Programa Genético. Elas foram modeladas diferentemente para os casos nos quais os atributos são textuais ou categóricos, sendo que a modelagem para atributos numéricos foi deixada como trabalho futuro. Em suma, métricas que realizam cálculos baseados em frequência de termos e documentos não puderam ser usadas para atributos categóricos, porém todas as demais foram. Dessa forma, na Seção~\ref{subsec::pg_metricas_conteudo_textual} temos as métricas que foram modeladas única e exclusivamente para serem utilizadas na tarefa de classificação de textos e na Seção~\ref{subsec::pg_metricas_conteudo} temos as métricas que foram estendidas e estão sendo usadas para classificação categórica, além da textual.

\subsection{Métricas Modeladas Para Atributos Textuais Exclusivamente.}
\label{subsec::pg_metricas_conteudo_textual}

As métricas usadas para atributos textuais consistem em algumas variantes do \textit{TFIDF}, métrica mais difundida entre as apresentadas. Na tabela~\ref{table::metricas_textuais}, temos apresentados algumas expressões amplamente utilizadas nas métricas aqui listadas.

\begin{table}[ht*]
\centering
\begin{tabular}{|c|c|}
\toprule
    \textbf{Expressão} & \textbf{Explicação} \\
\midrule
    $N$           & Número de documentos na base de treinamento. \tabularnewline \hline
    $M$           & Número de classes da coleção. \tabularnewline \hline
    $DF_{x_i} $   & Número de documentos do conjunto do treino que contém o termo $x_i$. \tabularnewline \hline
    $DF_{x_ic_j}$ & Número de documentos do treino com o termo $x_i$ e pertencentes a classe $c_j$. \tabularnewline \hline
    $CF_{x_i}$    & Número de classes em que o termo $x_i$ ocorre. \tabularnewline \hline 
    $F_{x_i}$     & Número de vezes que o termo $x_i$ aparece nos documentos de treinamento. \tabularnewline \hline
    $F_{x_ic_j}$  & Número de vezes que o termo $x_i$ aparece em documentos da classe $c_j$ no treino. \tabularnewline 
\bottomrule
\end{tabular}
\caption{Explicação das principais expressões utilizadas para definição das métricas para atributos textuais.}
\label{table::metricas_textuais}
\end{table}


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Frequência do Termo (TF)}
\label{subsubsection::sumtf}

A frequência de um termo, \textit{TF} da expressão em inglês, \textit{Term Frequency}, é simplesmente o número de vezes que um termo aparece na coleção de treinamento. Utilizamos o logaritmo desse valor como um fator normalizador, para evitar que termos muito frequentes dominem a função de credibilidade:
\begin{equation}\label{eqn::sumtf}
   TF(x_i) = 1.0 + \log{ ( F_{x_i} ) }
\end{equation}


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Frequência do Termo por Classe (TFClasse)}
\label{subsubsection::tf}

A frequência de um termo em uma classe, \textit{TFClasse}, segue o mesmo padrão utilizado pela métrica \textit{TF}, porém dessa vez contamos apenas os termos que aparecem em uma dada classse $c_j$:
\begin{equation}\label{eqn::tf}
   TFClasse(x_i, c_j) = 1.0 + \log{ ( F_{x_ic_j} ) }
\end{equation}


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Frequência dos Documentos por Termo (DF)}
\label{subsubsection::df}

A métrica \textit{DF}, do inglês, \textit{Document Frequency}, procura analisar a importância de um termo em relação ao número de documentos que o mesmo aparece:
\begin{equation}\label{eqn::df}
   DF(x_i) = 1.0 + \log{ ( DF_{x_i} ) }
\end{equation}


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Frequência de Documentos por Termo-Classe (DFClasse)}
\label{subsubsection::sumdf}

A métrica \textit{DFClasse} apenas avalia o número de documentos que um termo aparece em relação a uma classe específica, tentando capturar a importância de um termo para uma classe em relação ao número de documentos onde aquele termo está presente:
\begin{equation}\label{eqn::sumtf}
   DFClasse(x_i,c_j) = 1.0 + \log{ ( DF_{x_ic_j} ) }
\end{equation}


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Inverso da Frequência de Documentos (IDF)}
\label{subsubsection::idf}

O Inverso da Frequência de Documentos, \textit{IDF} do inglês \textit{Inverse Document Frequency}, é uma conhecida métrica que avalia a popularidade de um determinado termo em um conjunto de documentos. Temos que quanto mais popular é um termo ao longo dos documentos de uma coleção, pior é sua capacidade de discriminação, logo:
\begin{equation}\label{eqn::tficf}
   IDF(x_i) = \log( \frac{|N|} {DF(x_i)} )
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Inverso da Frequência de Documentos por Classe (IDFClasse)}
\label{subsubsection::idf}

O Inverso da Frequência de Documentos por classe, \textit{IDFClasse} é uma versão do \textit{IDF} em selecionamos somente documentos de uma dada classe:
\begin{equation}\label{eqn::tficf}
   IDFClasse(x_i,c_j) = \log( \frac{DF_{c_j}} {DF(x_ic_j)} )
\end{equation}


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Frequência do Termo Inverso da Frequência de Documentos (TFIDF)}
\label{subsubsection::tfidf}

Uma das métricas de pesos para atributos em classificação de textos mais populares na literatura é o \textit{TFIDF} (do inglês, \textit{Term Frequency Inversed Document Frequency}), ver \cite{Salton88}. O \textit{TFIDF} combina a frequência de um termo (\textit{Term Frequency}) que assume que múltiplas aparições de um termo em um documento é mais importante que aparições únicas com o inverso da frequência de um documento (\textit{Inverded Document Frequency}) que diz que termos raros são de maior poder discriminativo que termos muito frequentes. Em síntese, a fórmula de TFIDF é nada mais que a multiplicação das métricas TF e IDF, como já esperávamos:
\begin{equation}\label{eqn::tficf}
   TFIDF(x_i, c_j) =  F_{x_ic_j} \cdot \log( \frac{DF_{c_j}}{ DF_{x_ic_j} } )
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Frequência do Termo Inverso da Frequência da Classe (TFICF)}
\label{subsubsection::tficf}

O TFICF (do inglês, \textit{Term Frequency Inversed Class Frequency}) é uma variação do esquema TFIDF (ver Seção~\ref{subsubsection::tfidf}). Novamente, TF se refere a quanto importante é um termo em uma classe, pois trata-se de sua frequência; por sua vez, ICF é interpretado como a frequência relativa de um termo em uma classe. Como é possível observar, não existe uma forma de diferenciarmos entre um termo que aparece frequentemente em um pequeno subconjunto de documentos e um termo que está presente em um grande número de documentos entre as classes. Como mostrado por~\cite{ChihHow04}, a fórmula para TFICF é:
\begin{equation}\label{eqn::tficf}
   TFICF(x_i, c_j) = N_{x_ic_j} \cdot \log( \frac{M}{CF_{x_i}} )
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Category Term Description}
\label{subsubsection::ctd}

Definido por~\cite{ChihHow04}, \textit{Category Term Description} é uma métrica de seleção de atributos para classificação textual baseada em TFIDF (Seção~\ref{subsubsection::tfidf}) e TFICF (Seção~\ref{subsubsection::tficf}). How et al. propõe uma melhoria ao TDICF acreditando que quanto menos um termo ocorre entre os documentos, maior o poder discriminativo daquele termo, logo:
\begin{equation}\label{eqn::cdt}
   CDT(x_i, c_j) = TFClass(x_i, c_j) \cdot ICF(x_i, c_j) \cdot IDFClass(x_i,c_j)
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Dominância}
\label{subsubsection::dom}

Dominância é uma métrica originalmente proposta em~\cite{Zaiane02} e utilizada mais recentemente no trabalho de~\cite{Rocha08} para criação do que foi chamado de janela temporal de um documento. Em suma, utilizado exclusivamente em classificação textual, o método normaliza a frequência de um documento em um classe por todas as classes existentes, logo:

\begin{equation}\label{eqn::dom}
   Dominancia(x_i, c_j) = \frac{ DF_{x_ic_j} } { \sum\limits_{c_k \in \mathbb{C}} DF_{ x_ic_k } } 
\end{equation}

\subsubsection{MaxTFIDF}
\label{subsubsection::maxtfidf}

\subsubsection{MaxTFICF} 
\label{subsubsection::maxtficf}

\subsubsection{MaxCTD}
\label{subsubsection::maxctd}

\subsubsection{MaxDom}
\label{subsubsection::maxdom}



\subsection{Métricas Modeladas Para Atributos Textuais e Categóricos.}
\label{subsec::pg_metricas_conteudo}


Todas as métricas apresentadas nessa seção foram utilizadas para geração de uma função de credibilidade tanto para atributos textuais quanto para os categóricos. Elas são inspiradas em probabilidades que podem ser facilmente calculadas dos exemplos contidos no conjunto de treinamento. Destacamos que a probabilidade condicional $P(x_i|c_j)$ é a principal métrica, pois as demais, complexas ou não, são derivações dessa. Pretendemos através da Tabela~\ref{table::metricas_textuais_categoricos} mostrar as definições utilizadas para definição dos atributos categórico, lembrando que quando se trata de um problema de classificação de texto deve-se recorrer a Tabela~\ref{table::metricas_textuais}.


\begin{table}[ht*]
\centering
\begin{tabular}{|c|c|}
\toprule
    \textbf{Métrica} & \textbf{Explicação} \\
\midrule
    $N$           & Número de exemplos na base de treinamento. \tabularnewline \hline
    $M$           & Número de classes da coleção. \tabularnewline \hline
    $F_{x_ic_j}$  & Número de vezes que temos o atributo $A_i$ com o valor $x_i$ em exemplos da classe $c_j$. \tabularnewline \hline
    $F_{c_j}$     & Número de vezes que o atributo $A_j$ assume o valor $x_i$ em exemplos da classe $c_j$. \tabularnewline 
\bottomrule
\end{tabular}
\caption{Explicação das principais expressões utilizadas para definição das métricas para atributos categóricos.}
\label{table::metricas_textuais_categoricos}
\end{table}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Medida de Ambiguidade (AM)}
\label{subsubsection::am}

A medida de ambiguidade (AM de \textit{Ambiguity Measure}) foi definida por~\cite{Mengle08} e utilizada como um método de seleção de atributos. Ela atribui valores maiores para os atributos considerados menos ambíguos, onde um atributo é não ambíguo quando sua presença indica com um alto grau de confiança que o exemplo pertence a uma classe específica. Podemos calcular $AM(x_i, c_j)$ como:
\begin{equation}\label{eqn::am}
   AM(x_i, c_j) = \frac{ N_{x_{i}c_{j}}}{\sum\limits_{c_k \in \mathbb{C}} N_{x_{i}c_{k}}}.
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Probabilidade Condicional ($P(x_i|c_j)$)}
\label{subsubsection::pc}

A probabilidade condicional $P(x_i|c_j)$ provém do algoritmo \textit{Naïve Bayes} como foi discutido na Seção~\ref{subsec::cred_nb}.
Temos dois modos de calcular $P(x_i|c_j)$, um para quando temos $A_i$ categórico e outro para quando estamos realizando classificação textual.
A ideia principal de ambos é a mesma, para uma dada classe $c_j$, calculamos a probabilidade do atributo $A_i$ ter o valor $x_i$ entre todos possíveis. 
Para classificação categórica, basta apenas contar quantas vezes $A_i$ vale $x_i$ para uma dada classe $c_j$:
    \begin{equation}\label{eqn::nbcattexto}
        P(x_i|c_j) = \frac{ N_{x_{i}c_{j}} }{ N_{c_{j}} } 
    \end{equation}
%Onde $N_{x_{i}c_{j}}$ é o número de vezes que temos o termo $x_i$ nos exemplos de treino da classe $c_j$ e $N_{c_{j}}$ é o número de exemplos de treino da classe $c_j$.
        
Para classificação textual, contamos quantas vezes um termo aparece em uma classe em comparação a todos os termos possíveis:
    \begin{equation}\label{eqn::nbcattexto}
        P(x_i|c_j) = \frac{ N_{x_{i}c_{j}} }{ \sum\limits^{D}_{k = 1} {  N_{x_{k}c_{j}}} } 
    \end{equation}
%Onde $N_{x_{i}c_{j}}$ é o número de vezes que temos o termo $x_i$ nos documentos de treino da classe $c_j$ e $D$ é o número o vocabulário conhecido no treino.

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Inverso da Probabilidade Condicional ($P(x_i|c_j)$)}
\label{subsubsection::pc'}
Com o inverso da probabilidade condicional, calculamos a probabilidade de um atributo $A_i$ não valer $x_i$ para uma classe $c_j$. Podemos realizar esse calculo apenas com a seguinte fórmula:
\begin{equation}\label{eqn::plinhattalquec}
   P(\overline{x_i}|c_j) = 1.0 - P(x_i|c_j)
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Índice de Gini melhorado (GINI)}
\label{subsubsection::gini}

O índice de Gini é uma métrica baseada na curva de Lorenz que mostra a função de distribuição acumulada de uma variável. Esse índice é amplamente utilizado nas Ciências Econômicas como uma métrica para avaliação da distribuição de renda pela população de um certo país ou região. Infelizmente por essa métrica, o Brasil é um dos países mais desiguais do mundo (ver \cite{cia-gini}). 
Baseado na ideia de desigualdade, podemos pensar na distribuição de um atributo nas M classes possíveis. Um atributo que seja desigualmente distribuído é certamente um atributo com um maior poder de discriminação, e portanto, um atributo mais importante. O trabalho de~\cite{Shang07} consistiu na criação de um selecionador de atributos para classificadores textuais baseando-se no Índice de Gini, chamado Índice de Gini melhorado. Ao contrario da maioria das métricas expostas nessa seção, o Índice de Gini melhorado tem apenas um parâmetro, o valor do $i$-ésimo atributo, não levando em consideração nenhuma classe específica. Ele é considerado melhorado por algumas pequenas diferenças com o método tradicional de Gini, entre elas o fato de um maior valor se referir a um melhor atributo e não ao contrário como é feito no método original. A fórmula sugerida por \cite{Shang07} para ser utilizada em classificação de atributos textuais é dada por:
\begin{equation}\label{eqn::gini}
   GINI(x_i) = \sum\limits_{c_k \in \mathbb{C}} P(x_i|c_k)^2 \cdot P(c_k|x_i)^2
\end{equation}
Shang et al. destaca o fato da não utilização do fator $P(x_i)$, fazendo com que o Índice de GINI melhorado sofra menos a influência de atributos frequentes conseguindo capturar a capacidade de um atributo ser importante para distinguir uma classe, independente de qual classe é. Destacamos que $P(c|x_i)$ é justamente a probabilidade que o algoritmo Bayesiano pretende calcular, logo aproximamos esse fator como:
\begin{equation}\label{eqn::gini}
   P(c_j|x_i) = \frac{  P(c_j \wedge x_i) } { P(x_i) } = \frac{ \frac{ N_{x_ic_j}}{  \sum\limits_{c \in \mathbb{C}} \sum\limits_{k=1}^{D} {Nx_kc}  } } { \frac{\sum\limits_{c \in \mathbb{C}} N_{x_ic}}{ \sum\limits_{c \in \mathbb{C}} \sum\limits_{k=1}^{D} {Nx_kc}}} = \frac{ N_{x_{i}c_{j}}}{\sum\limits{c_k \in \mathbb{C}} N_{x_{i}c_{k}}}.
\end{equation}
Que é o mesmo valor definido por~\cite{Mengle08} para a métrica Medida da Ambiguidade mostrada na Seção~\ref{subsubsection::am}.

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Ganho de Informação}
\label{subsubsection::ig}

O Ganho de Informação (\textit{Information Gain}, IG), \cite{Yang97}, mede a diminuição da entropia quando um atributo é usado ou não. A entropia é uma medida utilizada no campo da Ciência da Informação que tenta quantificar a desordem, a imprevisibilidade. Quanto maior a entropia maior a entropia, mais difícil é prever um resultado, portanto a métrica IG seleciona os atributos que diminuam o valor da entropia, facilitando descobrir a qual classe um exemplo pertence. O Ganho da Informação pode ser calculado da seguinte forma:
\begin{equation}\label{eqn::ig}
   IG(x_i, c_j) = \sum_{c \in \{c_j, \overline{c_j}\}}\sum_{x \in \{x_i, \overline{x_i}\}}P(x|c)\log_2\frac{P(x|c)}{P(x)P(c)}.
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Cross Entropy}
\label{subsubsection::}

\textit{Cross Entropy} (CE), assim como o Índice de Gini Melhorado, Seção~\cite{subsubsection::gini}, apresenta apenas um parâmetro, um atributo. Novamente aproximamos o calculamos $P(c|x_i)$, pois esse já é o resultado do algoritmo \textit{Naïve Bayes} e, portanto, não o teríamos enquanto estamos calculando a credibilidade de um atributo em relação a uma classe. Assim como enunciado por~\cite{Koller97} e adaptado para seleção de atributos em~\cite{Mladenic98}, essa métrica assume a seguinte fórmula:
\begin{equation}\label{eqn::ce}
   CE(x_i) =  P(x_i) \cdot \sum_{c \in \mathbb{C}} P(c|x_i) \cdot \log_2 \frac{ P(c|x_i) } { P(c) }
\end{equation}

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{CHI-Quadrado}
\label{subsubsection::chi}

O teste \textit{CHI-quadrado - $\chi^2$} é utilizado no campo da Estatística para testar a independência entre dois eventos. Quando usado para seleção de atributos, tipicamente temos que os dois eventos são a ocorrência de uma classe e a ocorrência de um atributo $A_i$ com valor $x_i$, ver~\cite{Zheng03}. Logo,
\begin{equation}\label{eqn::chi}
   CHI(x_i, c_j) = N \cdot \frac{ [ P(x_i|c_j) \cdot P(\overline{x_i}|\overline{c_j}) - P(x_i|\overline{c_j}) \cdot P(\overline{x_i}|c_j) ]^2 } {P(x_i) \cdot P(\overline{x_i}) \cdot P(c_j) \ \cdot P(\overline{c_j}) }
\end{equation}
%como $P(x_i|c_j)$ a probabilidade de termos o atributo $A_i$ com valor $x_i$ dada a classe $c_j$ para classificação categórica e a probabilidade de um documento ter o termos $x_i$ dado que ele pertence a classe $c_j$. Valores próximos de zero indicam a falta de relação entre $x_i$ e $c_j$.

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Coeficiente de Correlação}
\label{subsubsection::cc}

O Coeficiente de Correlação (CC) é uma métrica de seleção de atributos, variante da métrica \textit{CHI-Quadrada - $\chi^2$}, ver Seção~\ref{subsubsection::chi}. Definida por~\cite{Ng97}, temos que $(CC)^2 = \chi^2$, logo:
\begin{equation}\label{eqn::ce}
   CC(x_i, c_j) = \sqrt{N} \cdot \frac{ P(x_i|c_j) \cdot P(\overline{x_i}|\overline{c_j}) - P(x_i|\overline{c_j}) \cdot P(\overline{x_i}|c_j) } {\sqrt{ P(x_i) \cdot P(\overline{x_i}) \cdot P(c_j) \ \cdot P(\overline{c_j}) } }.
\end{equation}
como a mesma definição de $P(x_i|c_j)$ usada para a métrica $\chi^2$. Os valores positivos para CC correspondem a pertinência do valor de um atributo a uma classe, enquanto valores negativos indicam a não pertinência. Quanto mais positivo (negativo) são os valores de CC, mais fortemente o atributo é relacionado (não relacionado) a uma classe. Para fins de seleção de atributo, valores mais elevados de CC são os mais interessantes, pois mostram uma correlação positiva entre um atributo e uma classe. Em contraste com CC, $\chi^2$ também considera importantes correlações negativas entre atributos e classes, o que acaba resultando que atributos que fortemente indicam a falta de pertinência a uma classe são tão importantes quanto os que indicam.

%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Coeficiente GSS}
\label{subsubsection::gss}
O coeficiente Galavotti–Sebastiani–Simi (GSS) introduzido por~\cite{Galavotti00} é bastante similar a $\chi^2$, Seção~\ref{subsubsection::chi}, e pode ser definido como:
\begin{equation}\label{eqn::gss}
   GSS(x_i, c_j) = P(x_i|c_j) \cdot P(\overline{x_i}|\overline{c_j}) - P(x_i|\overline{c_j}) \cdot P(\overline{x_i}|c_j).
\end{equation}
%sendo $P(x_i|c_j)$ definido na Seção~\ref{subsubsection::pc}. Da mesma forma como o Coeficiente de Correlação, Seção~\ref{subsubsection::cc}, valores positivos correspondem à pertinência de um atributo a uma categoria e, negativos, à não pertinência. 


%%%%%%%%%%%%%%%%%%%-------------------------------------------------------%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Razão de Chances - \textit{Odds Ratio} (OR)}
\label{subsubsection::or}

Proposta originalmente por~\cite{Rijsbergen79}, a métrica Razão de Chances, do inglês \textit{Odds Ration} (OR), também é uma métrica de seleção de atributos. A ideia básica é que a distribuição de atributos em exemplos relevantes é diferente da distribuição de atributos em exemplos não relevantes. Isso quer dizer que poderíamos definir dois eventos A e B e calculamos a probabilidade de ocorrência de A dividida pela probabilidade de não ocorrência de A e a comparamos com a probabilidade ocorrência de B dividida pela probabilidade de não ocorrência de B:
\begin{equation}\label{eqn::or}
   OR(A, B) = \frac{\frac{A}{1-A}} {\frac{B}{1-B}} = \frac{ A \cdot ( 1 - B )} { B \cdot ( 1 - A ) } .
\end{equation}
Uma razão de chances de 1.0 indica que ocorrer A ou B é igualmente provável, uma razão maior do que 1.0 indica que ocorrer A é mais provável, enquanto que uma razão de chances menor do que 1 indica que o evento B é tem uma probabilidade maior de ocorrer.

A razão de chances tem sido utilizada para selecionamento de atributos por \cite{Mladenic98} fazendo com que A seja $P(x_i|c_j)$ e B seja $P(x_i,\overline{c_j})$. Logo,
\begin{equation}\label{eqn::or}
   OR(x_i, c_j) = \frac{ P(x_i|c_j) \cdot [ 1.0 - P(x_i|\overline{c_j}) ] }{ [ 1.0 - P(x_i|c_j) ] \cdot P(x_i|\overline{c_j})}.
\end{equation}
%em que $P(x_i, c_j)$ é a probabilidade de termos o atributo $A_i$ com valor $x_i$ em exemplos que pertencem a classe $c_j$ e $P(x_i|\overline{c_j})$ é a probabilidade de termos $x_i$ em outras classes que não sejam $c_j$.

\subsubsection{MaxAM}
\label{subsubsection::maxam}

\subsubsection{MaxIG}
\label{subsubsection::maxig}

\subsubsection{MaxCHI}
\label{subsubsection::maxchi}

\subsubsection{MaxCC}
\label{subsubsection::maxcc}

\subsubsection{MaxOR}
\label{subsubsection::maxor}

\subsubsection{MaxGSS}
\label{subsubsection::maxgss}


\section{Credibilidade baseada em Grafos}
\label{sec::pg_cred_baseada_grafos}

\subsection{Métricas modeladas.}
\label{subsec::pg_metricas_grafos}

asdfsad


\subsubsection{NeighborhoodSize3(id,className,graphId)}
\label{subsubsection::neighborhoodsize}

break;
%\subsubsection{getHubScore(id, className, graphId)}
%break;
%QUAL A TRADUCAO DE HUB?


\subsubsection{Closeness}
\label{subsubsection::closeness}

De maneira intuitiva, dizemos que dois objetos estão próximos se eles estão a uma distância arbitrariamente pequena um do outro. Muitas vezes, entretanto, não é fácil estipular o que vem a ser uma distância pequena. Em teoria dos grafos, medimos a distância entre os vértices utilizando o calculo conhecido como caminho mínimo que conta o número mínimo de vértices que necessitamos atravessar para ligar dois vértices escolhidos em um grafo. \textit{Closeness} é uma métrica que calcula a proximidade de um vértice $v$ em relação a todo o grafo usando a média dos caminhos mínimos de $v$ para todos os outros vértices alcançáveis a partir de $v$, ver~\cite{Beauchamp65}. Dessa forma, podemos medir a importância de um vértice calculando quanto tempo em média é gasto para uma informação se espalhar a partir de um vértice $v$ para todo o resto do grafo. Por fim, são considerados vértices mais ``próximos'' aqueles que minimizam esse tempo.

\subsubsection{Betweenness}
\label{subsubsection::constraint}
A métrica de centralidade denominada \textit{Betweenness} se baseia no fato que um vértice é importante em um grafo se ele está entre o caminho de outros vértice, ou seja, um vértice é importante por estar sempre conectando outros vértices em um grafo. O algoritmo do caminho mínimo é o que se utiliza para percorrer da melhor maneira possível uma dada distância em um grafo e portanto, \textit{betweenness} calcula a importância de um vértice contando quantas vezes aquele vértice participa do caminho mínimo entre quaisquer dois outros vértices do grafo em questão, ver~\cite{Sabidussi66}. Obviamente, um vértice central que está no caminho mínimo de vários outros tem mais acesso a informação que circula pelo grafo que um vértice periférico com poucas ligações.

\subsubsection{Eigenvector Centrality}
\label{subsubsection::eigenvector}
A centralidade do Autovetor, em inglês \textit{Eigenvector Centrality}, também é uma medida de centralidade que avalia a importância de um vértice em todo o grafo. Ela atribui valores aos vértices baseados nas conexões que os mesmos têm, sendo que um vértice ganhará uma importância maior se estiver conectado a vértices de maior importância. De maneira matemática, dado que $x_i$ é o valor atribuído ao vértice $i$ e que podemos montar a matriz de adjacência $A$ com os $N$ vértices do grafo, na qual $A_{ij} = 1$ se existe uma aresta entre $i$ e $j$ e $A_{ij}=0$, caso contrário, temos:
\begin{equation}\label{eqn::eigenvector1}
   x_i = \frac{1}{\lambda} \cdot \sum\limits_{j=1}^{N} A_{ij} \cdot x_j
\end{equation}
Que pode ser rescrita utilizando vetores como:
\begin{equation}\label{eqn::eigenvector2}
   X = \frac{1}{\lambda} AX  \;\; \Longleftrightarrow\;\;  AX = \lambda X
\end{equation}
Onde $X$ é dito ser o \textit{autovetor} formado pelos valores de $x_i$ com $0 \leq i \leq N$ e associado ao \textit{autovalor} $\lambda$.  Podem existir muitos valores para $\lambda$ para os quais a Equação~\ref{eqn::eigenvector2} possui solução. Entretanto se utilizarmos todos os valores do \textit{autovetor} como positivos, teremos um único e maior possivel valor para o \textit{autovetor}, ver~\cite{Newman10}. Vale resaltar que o algoritmo \textit{PageRank}, Seção~\ref{subsubsection::pagerank}, é uma variação desse.


\subsubsection{Hub e Autoridade de Kleinberg (Hub e Auth)}
\label{subsubsection::hub}
As métricas conhecidas como Hub e Autoridade de Kleinberg são provenientes do trabalho de~\cite{Kleinberg99}. Elas também são conhecidas pelo nome de algoritmo \textit{Hyperlink-Induced Topic Search} (HITS) e por serem predecessoras do algoritmo \textit{PageRank}, Seção~\ref{subsubsection::pagerank}. Em suma, na \textit{Web}, algumas páginas são conhecidas como \textit{hubs} por não serem especialistas em nenhum assunto específico, mas possuírem ligações para vários outras páginas que são especialistas em seus respectivos assuntos, sendo, portanto, \textit{autoridades} no assunto tratado. Logo, o que temos é que um bom \textit{hub} é representado por uma página (vértice, no grafo que a \textit{Web} representa) que aponta para várias autoridades e uma boa autoridade é aquela apontada por vários \textit{hubs}. Uma página com poucas ligações e com poucas referências não é nem um bom \textit{hub} e nem uma boa autoridade.

\subsubsection{getPageRank(id, className, graphId)}
\label{subsubsection::pagerank}
break;



\subsubsection{getStrength(id, className, graphId)}
\label{subsubsection::strength}
break;

\subsubsection{Burt's Constraint}
\label{subsubsection::constraint}
\cite{Burt04}
break;

\subsubsection{getBibCoupling(id, className, graphId)}
break;
\subsubsection{getCoCitation(id, className, graphId)}
break;
\subsubsection{getJaccardSimilarity(id, className, graphId)}
break;
\subsubsection{getDiceSimilarity(id, className, graphId)}
break;
\subsubsection{getInverseLogSimilarity(id, className, graphId)}
break;
\subsubsection{getAvgNearstNeighborDegree(id, className, graphId)}
acho que nao to uando

